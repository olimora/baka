{
    "collab_server" : "",
    "contents" : "# script na naplnanie databazy\n#vymaze vsetko okrem funkcii\n#rm(list = setdiff(ls(), lsf.str()))\noptions(digits = 6)\nlibrary(\"RPostgreSQL\")\nlibrary(\"neuralnet\")\nlibrary(\"sirad\")\nlibrary('plyr')\nlibrary(\"randomForest\")\nsource('~/GitHub/baka/R source/funkcie.R')\n\n# nastavenia a premenne\n{\n  e <- list()\n  e$gho <- TRUE\n  e$teplota <- TRUE\n  e$vietor <- TRUE\n  e$oblacnost <- F\n  e$vlhkost <- F\n  e$tlak <- F\n  e$azim <- F\n  e$zen <- F\n  e$elev <- F\n  e$dlzkadna <- F\n  e$den_hod <- c(\"den\", \"hod\")[1]\n  e$fve <- c(\"FVE Dubravy 1\", \"FVE Dubravy 2\", \"FVE Plesivec\")\n  e$tren_mnoz <- \"najpodobnejsich 20\"\n  e$tren_mnoz_velkost <- 60\n  e$tren_mnoz_select <- \"select datum, sum(gho) gho, sum(teplota) teplota,\n  \t\t                          sum(vietor) vietor, sum(praca) praca\n                          from v_data\n                          where fve_nazov = '%s'\n                          group by datum\n                          order by datum\"\n  e$tren_mnoz_opis <- \"vyber 20 najpodobnejsich dni podla scitaneho gho, teploty, vetra.\n                        normalizovane na rozsah(skalu) medzi min a max za vsetky data elektrarne.\n                        gho * 90, teplota * 10, vietor * 1.\"\n  e$neural <- TRUE\n  e$neural_layers <- \"c(3,2)\"\n  e$neural_threshold <- 0.01  #0.01 default\n  e$neural_algorithm <- c(\"backprop\", \"rprop+\", \"rprop-\", \"sag\", \"slr\")[2] # default je rprop+\n  e$neural_startweights <- \"rep(1, n$pocet_vah) # vektor jednotiek\"\n  e$forest <- TRUE\n  e$forest_ntree <- 0 # 0 ak default\n  e$forest_mtry <- 0 # 0 ak default\n  \n  n <- list()\n  n$input_v <- c(e$gho, e$teplota, e$vietor, e$oblacnost, e$vlhkost, \n                 e$tlak, e$azim, e$zen, e$elev, e$dlzkadna)\n  n$pocet_vah <- compute_weigths_num(length(subset(n$input_v, n$input_v == TRUE)),\n                                     unq(e$neural_layers))\n  n$net <- 0\n  n$output <- 0\n  n$stats <- 0\n  \n  f <- list()\n  f$forest <- 0\n  f$output <- 0\n  f$stats <- 0\n  \n  t <- list()\n  t$all_days <- 0\n  t$all_days_count <- 0\n  t$chosen_one\n  t$not_i <- 0\n  t$differ <- 0\n  t$train_set <- 0\n  t$ordered <- 0\n  t$actual <- 0\n\n  prog <- list()\n  prog$printed <- -10\n  prog$print_perc <- 0\n  prog$print_perc_all <- 0\n  prog$baseAll <- 0\n  prog$basePart <- 0\n  prog$i <- 0\n  prog$actual_time <- 0\n  prog$estimated_time <- 0\n  prog$diff <- 1\n  \n  scale <- list()\n  scale$maxims <- 0\n  scale$minims <- 0\n  scale$scale <- 0\n  \n  time <- list()\n  time$start <- 0\n  time$end <- 0\n  \n  db <- list()\n  db$drv <- 0\n  db$con <- 0\n  db$result <- 0\n  \n}\n\n#na meranie casu\ntime$start <- Sys.time()\n\ndb$drv <- dbDriver(\"PostgreSQL\")\nif (exists(\"db$con\")) dbDisconnect(db$con)\ndb$con <- getConnection(db$drv)\nprog$baseAll <- dbGetQuery(db$con, \"SELECT count(*) FROM\n                               (SELECT DISTINCT datum, fve FROM t_produkcia) s\")\ndbDisconnect(db$con)\n\nstats_all <- data.frame()\nfor (fve in 1:length(e$fve)) {\n  if (exists(\"db$con\")) dbDisconnect(db$con)\n  db$con <- getConnection(db$drv)\n  t$all_days <- dbGetQuery(db$con, sprintf(e$tren_mnoz_select, e$fve[fve]))\n  dbDisconnect(db$con)\n  \n  scale$maxims <- c(max(t$all_days[,2]), max(t$all_days[,3]), max(t$all_days[,4]))\n  scale$minims <- c(min(t$all_days[,2]), min(t$all_days[,3]), min(t$all_days[,4]))\n  scale$scale <- abs(scale$maxims - scale$minims)\n  \n  t$actual <- c()\n  n$output <- c()\n  f$output <- c()\n  \n  t$all_days_count <- nrow(t$all_days)\n  prog$basePart <- t$all_days_coun\n  prog$printed <- -10\n  \n  for (i in 1:t$all_days_count) { #t$all_days_count\n    # pre kazdy den vybrat trenovaciu mnozinu\n    # vsetky okrem toho pre ktory idem predikovat\n    t$chosen_one <- t$all_days[i,]\n    t$not_i <- c(i != c(1:t$all_days_count))\n    t$train_set <- t$all_days[t$not_i,]\n    \n    # vypocitat podobnost\n    t$differ <- c()\n    for (j in 1:nrow(t$train_set)) { #nrow(t$train_set)\n      t$differ[j] <- (\n        90 * (abs(t$chosen_one['gho'] - t$train_set[j,'gho']) %p% scale$scale[1]) \n        +\n        10 * (abs(t$chosen_one['teplota'] - t$train_set[j,'teplota']) %p% scale$scale[2])\n        +\n        (abs(t$chosen_one['vietor'] - t$train_set[j,'vietor']) %p% scale$scale[3])\n      )\n    }\n    t$train_set['diff'] <- unlist(t$differ)\n    #t$train_set <- t$train_set[c(t$train_set[,6] < 3),]\n    #print(nrow(t$train_set))\n    \n    t$ordered <- arrange(t$train_set, t$train_set[,6])\n    t$train_set <- t$ordered[1:e$tren_mnoz_velkost,]\n    t$actual <- vector.add(t$actual, t$chosen_one[1,'praca'])\n    \n    # do db tabulky pocet hidden layer a trueshold\n    n$net <- neuralnet(praca~gho+teplota+vietor, t$train_set, startweights = unq(e$neural_startweights),\n                          hidden=unq(e$neural_layers), threshold=e$neural_threshold)\n    n$output <- vector.add(n$output, compute(n$net, t$chosen_one[1,2:4])$net.result)\n    #plot(n$net)\n    \n    f$forest <- randomForest(praca~gho+teplota+vietor, data=t$train_set, importance=TRUE, proximity=TRUE)\n    f$output <-  vector.add(f$output, predict(f$forest, t$chosen_one[1,2:4], type=\"response\", norm.votes=TRUE))\n    #plot(f$forest, type=\"l\")\n    \n    prog$i <- prog$i + 1\n    prog$print_perc <- (i %p% prog$basePart)\n    if (prog$print_perc >= prog$printed + prog$diff) {\n      prog$print_perc_all <- (prog$i %p% prog$baseAll)\n      prog$actual_time <- as.numeric(difftime(Sys.time(), time$start, units = \"sec\"))\n      prog$estimated_time <- prog$actual_time * 100 / prog$print_perc_all$count\n      print(sprintf(\"Progress: %.02f%s all, FVE(%d): %.02f%s, Estimated time: %s, Actual: %s\",\n                    prog$print_perc_all, \"%\", fve, prog$print_perc, \"%\",\n                    format.time(prog$estimated_time),\n                    format.time(prog$actual_time)),\n            quote=F)\n      prog$printed <- prog$print_perc\n    }\n  }\n  \n  # statistika presnosti\n  if (exists(\"db$con\")) dbDisconnect(db$con)\n  db$con <- getConnection(db$drv)\n  \n  n$stats <- all_statistics(t$actual, n$output)\n  db$result <- dbGetQuery(db$con, build_insert_stats.neur(e, n$stats, time$start))\n  \n  f$stats <- all_statistics(t$actual, f$output)\n  db$result <- dbGetQuery(db$con, build_insert_stats.forest(e, f$stats, time$start))\n  \n  dbDisconnect(db$con)\n}\n\ntime$end <- Sys.time()\nprint(paste(\"Celkovy cas =\", format.time(difftime(time$end, time$start, units = \"sec\"))))\n\ndbDisconnect(db$con)\ndbUnloadDriver(db$drv)\n#rm(list = setdiff(ls(), lsf.str()))",
    "created" : 1462651441401.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "727096888",
    "id" : "800C95D2",
    "lastKnownWriteTime" : 1458905875,
    "last_content_update" : 1458905875,
    "path" : "~/GitHub/baka/R source/predikcia.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}