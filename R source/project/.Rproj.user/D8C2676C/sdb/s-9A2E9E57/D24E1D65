{
    "collab_server" : "",
    "contents" : "# script na naplnanie databazy\n#vymaze vsetko okrem funkcii\n#rm(list = setdiff(ls(), lsf.str()))\noptions(digits = 6)\nlibrary(RPostgreSQL)\nlibrary(neuralnet)\nlibrary(sirad)\nlibrary(plyr)\nlibrary(randomForest)\nsource('~/GitHub/baka/R source/project/functions.R')\n\n# nastavenia a premenne\n{\n  e <- list()\n  e$gho <- TRUE\n  e$teplota <- TRUE\n  e$vietor <- TRUE\n  e$oblacnost <- TRUE\n  e$vlhkost <- TRUE\n  e$tlak <- F\n  e$azim <- F\n  e$zen <- F\n  e$elev <- TRUE\n  e$dlzkadna <- TRUE\n  e$den_hod <- c(\"den\", \"hod\")[1]\n  e$fve <- c(\"FVE Dubravy 1\", \"FVE Dubravy 2\", \"FVE Plesivec\")[3]\n  e.fve <- e$fve\n  e$tren_mnoz <- \"najpodobnejsich 60\"\n  e$tren_mnoz_velkost <- 60\n  e.tren_mnoz_velkost <- e$tren_mnoz_velkost\n  e$tren_mnoz_select <- \"select datum, sum(praca) praca, sum(gho) gho, sum(teplota) teplota, sum(vietor) vietor,\n  sum(oblacnost) oblacnost, sum(vlhkost) vlhkost, max(dlzkadna) dlzkadna, max(elev) elev\n  from v_data where fve_nazov = '%s'group by datum order by datum\"\n  e.tren_mnoz_select <- e$tren_mnoz_select\n  e$tren_mnoz_opis <- \"vyber 60 najpodobnejsich dni podla scitaneho gho, teploty, vetra, oblacnosti, vlhkosti, \n  maximalnej dlzky dna a elevacie.\n  normalizovane na rozsah(skalu) medzi min a max za vsetky data elektrarne.\n  gho * 1, teplota * 1, oblacnost * 1, dlzkadna * 1\"\n  e$podobnost <- \"1*gho, 1*teplota, 1*oblacnost, 1*dlzkadna\"\n  formula <- unq(\"praca~gho+teplota+vietor+oblacnost+vlhkost+dlzkadna+elev\")\n  e$neural <- TRUE\n  e$neural_layers <- \"c(7,5,3)\"\n  e.neural_layers <- unq(e$neural_layers)\n  e$neural_threshold <- 0.01  #0.01 default\n  e.neural_threshold <- e$neural_threshold\n  e$neural_algorithm <- c(\"backprop\", \"rprop+\", \"rprop-\", \"sag\", \"slr\")[2] # default je rprop+\n  e.neural_algorithm <- e$neural_algorithm\n  e$neural_startweights <- \"rep(1, n.pocet_vah)\"\n  e.neural_startweights <- unq(e$neural_startweights)\n  e$forest <- TRUE\n  e$forest_ntree <- 500 # 0 ak default\n  e.forest_ntree <- e$forest_ntree\n  e$forest_mtry <- 7 # 0 ak default\n  e.forest_mtry <- e$forest_mtry\n  \n  n.input_v <- c(e$gho, e$teplota, e$vietor, e$oblacnost, e$vlhkost, e$tlak, e$azim, e$zen, e$elev, e$dlzkadna)\n  n.pocet_vah <- compute_weigths_num(length(subset(n.input_v, n.input_v == TRUE)), e.neural_layers)\n  n.net <- 0\n  n.output <- 0\n  n.stats <- 0\n  \n  f.forest <- 0\n  f.output <- 0\n  f.stats <- 0\n  \n  t.all_days <- 0\n  t.all_days_count <- 0\n  t.chosen_one <- 0\n  t.not_i <- 0\n  t.differ <- 0\n  t.train_set <- 0\n  t.ordered <- 0\n  t.actual <- 0\n  \n  prog.printed <- -10\n  prog.print_perc <- 0\n  prog.print_perc_all <- 0\n  prog.baseAll <- 0\n  prog.basePart <- 0\n  prog.i <- 0\n  prog.actual_time <- 0\n  prog.estimated_time <- 0\n  prog.diff <- 0\n  \n  scale.maxims <- 0\n  scale.minims <- 0\n  scale.scale <- 0\n  \n  time.start <- 0\n  time.end <- 0\n  \n  db.drv <- 0\n  db.result <- 0\n  \n  vzorka <- 100\n  \n}\n\n#na meranie casu\ntime.start <- Sys.time()\n\ndb.drv <- dbDriver(\"PostgreSQL\")\nif (exists(\"db.con\")) dbDisconnect(db.con)\n# db.con <- getConnection(db.drv)\n# prog.baseAll <- dbGetQuery(db.con, \"SELECT count(*) FROM\n#                            (SELECT DISTINCT datum, fve FROM t_produkcia WHERE fve = 3) s\")\n# prog.baseAll <- prog.baseAll$count\n# dbDisconnect(db.con)\n\nntree_v <- c(100, 300, 500)\nmtry_v <- c(2:7)\ntren_velk_v <- c(30, 60, 90, 120)\n\nprog.baseAll <- length(ntree_v) * length(mtry_v) * length(tren_velk_v) * vzorka\n\nfor (ntree_i in ntree_v) {\n  e$forest_ntree <- ntree_i \n  e.forest_ntree <- ntree_i\n  \n  for (mtry_i in mtry_v) {\n    e$forest_mtry <- mtry_i \n    e.forest_mtry <- mtry_i\n    \n    for (tren_velk_i in tren_velk_v) {\n      e$tren_mnoz <- sprintf(\"najpodobnejsich %d\", tren_velk_i)\n      e$tren_mnoz_velkost <- tren_velk_i\n      e.tren_mnoz_velkost <- tren_velk_i\n      \n      for (fve in 1:length(e.fve)) { #length(e.fve)\n        if (exists(\"db.con\")) dbDisconnect(db.con)\n        db.con <- getConnection(db.drv)\n        t.all_days <- dbGetQuery(db.con, sprintf(e.tren_mnoz_select, e.fve[fve]))\n        dbDisconnect(db.con)\n        \n        scale.maxims <- c(max(t.all_days[,3]), max(t.all_days[,4]), max(t.all_days[,5]), \n                          max(t.all_days[,6]), max(t.all_days[,7]), max(t.all_days[,8]), max(t.all_days[,9]))\n        scale.minims <- c(min(t.all_days[,3]), min(t.all_days[,4]), min(t.all_days[,5]), \n                          min(t.all_days[,6]), min(t.all_days[,7]), min(t.all_days[,8]), min(t.all_days[,9]))\n        scale.scale <- abs(scale.maxims - scale.minims)\n        \n        all_days_zaloha <- t.all_days\n        \n        rand_vec <- c()\n        while (length(rand_vec) < vzorka) {\n          rand <- round(runif(1, 1, nrow(t.all_days)), 0)\n          if (!rand %in% rand_vec) {\n            rand_vec <- vector.add(rand_vec, rand)\n          }\n        }\n        t.all_days <- t.all_days[rand_vec,]\n        \n        t.all_days_count <- nrow(t.all_days)\n        prog.basePart <- t.all_days_count\n        prog.printed <- -10\n        \n        t.actual <- c()\n        n.output <- c()\n        f.output <- c()\n        \n        for (i in 1:t.all_days_count) { #t.all_days_count\n          # pre kazdy den vybrat trenovaciu mnozinu\n          # vsetky okrem toho pre ktory idem predikovat\n          #i = 1\n          t.chosen_one <- t.all_days[i,]\n          t.not_i <- c(t.chosen_one[1,'datum'] != all_days_zaloha[,'datum'])\n          t.train_set <- all_days_zaloha[t.not_i,] \n          \n          # vypocitat podobnost\n          t.differ <- c()\n          for (j in 1:nrow(t.train_set)) { #nrow(t.train_set)\n            t.differ[j] <- (\n              (abs(t.chosen_one['gho'] - t.train_set[j,'gho']) * 100 / scale.scale[1]) \n              +\n                (abs(t.chosen_one['teplota'] - t.train_set[j,'teplota']) * 100 / scale.scale[2])\n              +\n                (abs(t.chosen_one['oblacnost'] - t.train_set[j,'oblacnost']) * 100 / scale.scale[4]) \n              +\n                (abs(t.chosen_one['dlzkadna'] - t.train_set[j,'dlzkadna']) * 100 / scale.scale[6])\n            )\n          }\n          \n          t.train_set['diff'] <- unlist(t.differ)\n          #t.train_set <- t.train_set[c(t.train_set[,6] < 3),]\n          \n          t.ordered <- arrange(t.train_set, t.train_set[,'diff'])\n          t.train_set <- t.ordered[1:e.tren_mnoz_velkost,]\n          t.actual <- vector.add(t.actual, t.chosen_one[1,'praca'])\n          \n          f.forest <- randomForest(formula, data=t.train_set, ntree = e.forest_ntree, mtry = e.forest_mtry,\n                                   importance=TRUE, proximity=TRUE)\n          f.output <-  vector.add(f.output, predict(f.forest, t.chosen_one[1,3:ncol(t.chosen_one)], type=\"response\", norm.votes=TRUE))\n          #plot(f.forest, type=\"l\")\n          \n          prog.i <- prog.i + 1\n          #prog.print_perc <- (i * 100 / prog.basePart)\n          prog.print_perc_all <- (prog.i * 100 / prog.baseAll)\n          if (prog.print_perc_all >= prog.printed + prog.diff) {\n            prog.actual_time <- as.numeric(difftime(Sys.time(), time.start, units = \"sec\"))\n            prog.estimated_time <- prog.actual_time * 100 / prog.print_perc_all\n            print(sprintf(\"Forest: %03.2f%s all, p: %00000.d/%00000.d, Estimated time: %s, Actual: %s\",\n                          prog.print_perc_all, \"%\", prog.i, prog.baseAll,\n                          format.time(prog.estimated_time),\n                          format.time(prog.actual_time)),\n                  quote=F)\n            prog.printed <- prog.print_perc_all\n          }\n        }\n        \n        # statistika presnosti\n        if (exists(\"db.con\")) dbDisconnect(db.con)\n        db.con <- getConnection(db.drv)\n        f.stats <- all_statistics(t.actual, f.output)\n        db.result <- dbGetQuery(db.con, build_insert_stats.forest(e, f.stats, time.start, fve))\n        dbDisconnect(db.con)\n      }\n      \n    }\n  }\n}\n\n\n\n\ntime.end <- Sys.time()\nprint(paste(\"Celkovy cas =\", format.time(difftime(time.end, time.start, units = \"sec\"))))\n\ndbDisconnect(db.con)\ndbUnloadDriver(db.drv)\n#rm(list = setdiff(ls(), lsf.str()))",
    "created" : 1458927200269.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1105889093",
    "id" : "D24E1D65",
    "lastKnownWriteTime" : 1458939683,
    "last_content_update" : 1458939683619,
    "path" : "~/GitHub/baka/R source/project/prediction_script_03.R",
    "project_path" : "prediction_script_03.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}