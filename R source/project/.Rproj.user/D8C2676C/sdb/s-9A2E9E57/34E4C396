{
    "collab_server" : "",
    "contents" : "# script na naplnanie databazy\n#vymaze vsetko okrem funkcii\n#rm(list = setdiff(ls(), lsf.str()))\noptions(digits = 6)\nlibrary(RPostgreSQL)\nlibrary(neuralnet)\nlibrary(sirad)\nlibrary(plyr)\nlibrary(randomForest)\nsource('~/GitHub/baka/R source/project/functions.R')\n\n# nastavenia a premenne\n{\n  e <- list()\n  e$gho <- TRUE\n  e$teplota <- TRUE\n  e$vietor <- TRUE\n  e$oblacnost <- TRUE\n  e$vlhkost <- TRUE\n  e$tlak <- F\n  e$azim <- F\n  e$zen <- F\n  e$elev <- TRUE\n  e$dlzkadna <- TRUE\n  e$den_hod <- c(\"den\", \"hod\")[1]\n  e$fve <- c(\"FVE Dubravy 1\", \"FVE Dubravy 2\", \"FVE Plesivec\")\n  e.fve <- e$fve\n  e$tren_mnoz <- \"najpodobnejsich 30\"\n  e$tren_mnoz_velkost <- 30\n  e.tren_mnoz_velkost <- e$tren_mnoz_velkost\n  e$tren_mnoz_select <- \"select datum, sum(praca) praca, sum(gho) gho, sum(teplota) teplota, sum(vietor) vietor,\n  sum(oblacnost) oblacnost, sum(vlhkost) vlhkost, max(dlzkadna) dlzkadna, max(elev) elev\n  from v_data where fve_nazov = '%s'group by datum order by datum\"\n  e.tren_mnoz_select <- e$tren_mnoz_select\n  e$tren_mnoz_opis <- \"vyber 30 najpodobnejsich dni podla scitaneho gho, teploty, vetra, oblacnosti, vlhkosti, \n  maximalnej dlzky dna a elevacie.\n  normalizovane na rozsah(skalu) medzi min a max za vsetky data elektrarne.\n  gho * 50, teplota * 30, vietor * 5, oblacnost * 100, vlhkost * 1, dlzkadna * 50, elev * 1\"\n  formula <- unq(\"praca~gho+teplota+vietor+oblacnost+vlhkost+dlzkadna+elev\")\n  e$neural <- TRUE\n  e$neural_layers <- \"c(7,5,3)\"\n  e.neural_layers <- unq(e$neural_layers)\n  e$neural_threshold <- 0.01  #0.01 default\n  e.neural_threshold <- e$neural_threshold\n  e$neural_algorithm <- c(\"backprop\", \"rprop+\", \"rprop-\", \"sag\", \"slr\")[2] # default je rprop+\n  e.neural_algorithm <- e$neural_algorithm\n  e$neural_startweights <- \"rep(1, n.pocet_vah)\"\n  e.neural_startweights <- unq(e$neural_startweights)\n  e$forest <- TRUE\n  e$forest_ntree <- 0 # 0 ak default\n  e.forest_ntree <- e$forest_ntree\n  e$forest_mtry <- 0 # 0 ak default\n  e.forest_mtry <- e$forest_mtry\n  \n  n.input_v <- c(e$gho, e$teplota, e$vietor, e$oblacnost, e$vlhkost, e$tlak, e$azim, e$zen, e$elev, e$dlzkadna)\n  n.pocet_vah <- compute_weigths_num(length(subset(n.input_v, n.input_v == TRUE)), e.neural_layers)\n  n.net <- 0\n  n.output <- 0\n  n.stats <- 0\n  \n  f.forest <- 0\n  f.output <- 0\n  f.stats <- 0\n  \n  t.all_days <- 0\n  t.all_days_count <- 0\n  t.chosen_one <- 0\n  t.not_i <- 0\n  t.differ <- 0\n  t.train_set <- 0\n  t.ordered <- 0\n  t.actual <- 0\n  \n  prog.printed <- -10\n  prog.print_perc <- 0\n  prog.print_perc_all <- 0\n  prog.baseAll <- 0\n  prog.basePart <- 0\n  prog.i <- 0\n  prog.actual_time <- 0\n  prog.estimated_time <- 0\n  prog.diff <- 10\n  \n  scale.maxims <- 0\n  scale.minims <- 0\n  scale.scale <- 0\n  \n  time.start <- 0\n  time.end <- 0\n  \n  db.drv <- 0\n  db.con <- 0\n  db.result <- 0\n  \n}\n\n#na meranie casu\ntime.start <- Sys.time()\n\ndb.drv <- dbDriver(\"PostgreSQL\")\nif (exists(\"db.con\") & db.con != 0) dbDisconnect(db.con)\ndb.con <- getConnection(db.drv)\nprog.baseAll <- dbGetQuery(db.con, \"SELECT count(*) FROM\n                           (SELECT DISTINCT datum, fve FROM t_produkcia) s\")\ndbDisconnect(db.con)\n\nstats_all <- data.frame()\nfor (fve in 1:length(e.fve)) { #length(e.fve)\n  if (exists(\"db.con\")) dbDisconnect(db.con)\n  db.con <- getConnection(db.drv)\n  t.all_days <- dbGetQuery(db.con, sprintf(e.tren_mnoz_select, e.fve[fve]))\n  dbDisconnect(db.con)\n  \n  scale.maxims <- c(max(t.all_days[,3]), max(t.all_days[,4]), max(t.all_days[,5]), \n                    max(t.all_days[,6]), max(t.all_days[,7]), max(t.all_days[,8]), max(t.all_days[,9]))\n  scale.minims <- c(min(t.all_days[,3]), min(t.all_days[,4]), min(t.all_days[,5]), \n                    min(t.all_days[,6]), min(t.all_days[,7]), min(t.all_days[,8]), min(t.all_days[,9]))\n  scale.scale <- abs(scale.maxims - scale.minims)\n  \n  t.actual <- c()\n  n.output <- c()\n  f.output <- c()\n  \n  t.all_days_count <- nrow(t.all_days)\n  prog.basePart <- t.all_days_count\n  prog.printed <- -10\n  \n  for (i in 1:t.all_days_count) { #t.all_days_count\n    # pre kazdy den vybrat trenovaciu mnozinu\n    # vsetky okrem toho pre ktory idem predikovat\n    #i = 1\n    t.chosen_one <- t.all_days[i,]\n    t.not_i <- c(i != c(1:t.all_days_count))\n    t.train_set <- t.all_days[t.not_i,]\n    \n    # vypocitat podobnost\n    t.differ <- c()\n    for (j in 1:nrow(t.train_set)) { #nrow(t.train_set)\n      t.differ[j] <- (\n        50 * (abs(t.chosen_one['gho'] - t.train_set[j,'gho']) * 100 / scale.scale[1]) \n        +\n          30 * (abs(t.chosen_one['teplota'] - t.train_set[j,'teplota']) * 100 / scale.scale[2])\n        +\n          5 * (abs(t.chosen_one['vietor'] - t.train_set[j,'vietor']) * 100 / scale.scale[3])\n        +\n          100 * (abs(t.chosen_one['oblacnost'] - t.train_set[j,'oblacnost']) * 100 / scale.scale[4]) \n        +\n          1 * (abs(t.chosen_one['vlhkost'] - t.train_set[j,'vlhkost']) * 100 / scale.scale[5])\n        +\n          50 * (abs(t.chosen_one['dlzkadna'] - t.train_set[j,'dlzkadna']) * 100 / scale.scale[6])\n        +\n          1 * (abs(t.chosen_one['elev'] - t.train_set[j,'elev']) * 100 / scale.scale[7])\n      )\n    }\n    \n    t.train_set['diff'] <- unlist(t.differ)\n    #t.train_set <- t.train_set[c(t.train_set[,6] < 3),]\n    \n    t.ordered <- arrange(t.train_set, t.train_set[,'diff'])\n    t.train_set <- t.ordered[1:e.tren_mnoz_velkost,]\n    t.actual <- vector.add(t.actual, t.chosen_one[1,'praca'])\n    \n    # do db tabulky pocet hidden layer a trueshold\n    n.net <- neuralnet(formula, t.train_set, startweights = e.neural_startweights,\n                       hidden=e.neural_layers, threshold=e.neural_threshold)\n    n.output <- vector.add(n.output, compute(n.net, t.chosen_one[1,3:ncol(t.chosen_one)])$net.result)\n    #plot(n.net)\n    \n    f.forest <- randomForest(formula, data=t.train_set, importance=TRUE, proximity=TRUE)\n    f.output <-  vector.add(f.output, predict(f.forest, t.chosen_one[1,3:ncol(t.chosen_one)], type=\"response\", norm.votes=TRUE))\n    #plot(f.forest, type=\"l\")\n    \n    prog.i <- prog.i + 1\n    prog.print_perc <- (i * 100 / prog.basePart)\n    if (prog.print_perc >= prog.printed + prog.diff) {\n      prog.print_perc_all <- (prog.i * 100 / prog.baseAll)\n      prog.actual_time <- as.numeric(difftime(Sys.time(), time.start, units = \"sec\"))\n      prog.estimated_time <- prog.actual_time * 100 / prog.print_perc_all$count\n      print(sprintf(\"Progress: %03.f%s all, FVE(%d): %03.f%s, Estimated time: %s, Actual: %s\",\n                    prog.print_perc_all, \"%\", fve, prog.print_perc, \"%\",\n                    format.time(prog.estimated_time),\n                    format.time(prog.actual_time)),\n            quote=F)\n      prog.printed <- prog.print_perc\n    }\n  }\n  \n  # statistika presnosti\n  if (exists(\"db.con\")) dbDisconnect(db.con)\n  db.con <- getConnection(db.drv)\n  \n  n.stats <- all_statistics(t.actual, n.output)\n  db.result <- dbGetQuery(db.con, build_insert_stats.neur(e, n.stats, time.start, fve))\n  \n  f.stats <- all_statistics(t.actual, f.output)\n  db.result <- dbGetQuery(db.con, build_insert_stats.forest(e, f.stats, time.start, fve))\n  \n  dbDisconnect(db.con)\n}\n\ntime.end <- Sys.time()\nprint(paste(\"Celkovy cas =\", format.time(difftime(time.end, time.start, units = \"sec\"))))\n\ndbDisconnect(db.con)\ndbUnloadDriver(db.drv)\n#rm(list = setdiff(ls(), lsf.str()))",
    "created" : 1458920465393.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1787359743",
    "id" : "34E4C396",
    "lastKnownWriteTime" : 1458927829,
    "last_content_update" : 1458927829187,
    "path" : "~/GitHub/baka/R source/project/prediction_script_02.R",
    "project_path" : "prediction_script_02.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}