to_see <- cbind(to_see, output)
to_see <- cbind(to_see, dif = abs(output - actual) * 100 / actual)
to_see <- arrange(to_see, to_see$dif)
db.drv <- dbDriver("PostgreSQL")
if (exists("db.con")) dbDisconnect(db.con)
db.con <- getConnection(db.drv)
to_see <-  dbGetQuery(db.con, "SELECT fve, cas, gho, oblacnost,
teplota, vietor, vlhkost, dlzkadna, elev, praca
FROM v_data ORDER BY fve, cas")
to_see <- cbind(to_see, output)
to_see <- cbind(to_see, dif = abs(output - actual) * 100 / actual)
to_see <- arrange(to_see, to_see$dif)
to_see
to_see
stats
source('~/GitHub/baka/R source/presentation_tests/paral_hod_all.R')
db.drv <- dbDriver("PostgreSQL")
if (exists("db.con")) dbDisconnect(db.con)
db.con <- getConnection(db.drv)
to_see <-  dbGetQuery(db.con, "SELECT fve, cas, gho, oblacnost,
teplota, vietor, vlhkost, dlzkadna, elev, praca
FROM v_data WHERE praca > 0 ORDER BY fve, cas")
to_see <- cbind(to_see, output)
to_see <- cbind(to_see, dif = abs(output - actual) * 100 / actual)
to_see <- arrange(to_see, to_see$dif)
stats
to_see
db.drv <- dbDriver("PostgreSQL")
if (exists("db.con")) dbDisconnect(db.con)
db.con <- getConnection(db.drv)
all_data <-  dbGetQuery(db.con, "SELECT fve, cas, gho, oblacnost,
teplota, vietor, vlhkost, dlzkadna, elev, praca
FROM v_data ORDER BY fve, cas")
to_see <- cbind(all_data, output)
to_see <- cbind(to_see, dif = abs(output - actual) * 100 / actual)
to_see <- arrange(to_see, to_see$dif)
all_data <-  dbGetQuery(db.con, "SELECT fve, cas, gho, oblacnost,
teplota, vietor, vlhkost, dlzkadna, elev, praca
FROM v_data ORDER BY fve, cas")
all_data <- cbind(all_data, output)
to_see <- cbind(all_data, dif = abs(output - actual) * 100 / actual)
to_see <- arrange(to_see, to_see$dif)
to_see
?ddply
all_data <-  dbGetQuery(db.con, "SELECT fve, datum, cas, gho, oblacnost,
teplota, vietor, vlhkost, dlzkadna, elev, praca
FROM v_data ORDER BY fve, cas")
all_data <- cbind(all_data, output)
to_see <- cbind(all_data, dif = abs(output - actual) * 100 / actual)
to_see <- arrange(to_see, to_see$dif)
to_see
ddply(all_data,~group,summarise,sumpraca=sum(praca),sumoutput=sum(output))
ddply(all_data,~datum,summarise,sumpraca=sum(praca),sumoutput=sum(output))
ddply(all_data,~datum,summarise, gho=sum(gho), oblacnost=sum(oblacnost),
teplota=sum(teplota), vietor=sum(vietor), vlhkost=sum(vlhkost),
dlzkadna=max(dlzkadna), praca=sum(praca),output=sum(output))
groupped <- ddply(all_data,~datum,summarise, gho=sum(gho), oblacnost=sum(oblacnost),
teplota=sum(teplota), vietor=sum(vietor), vlhkost=sum(vlhkost),
dlzkadna=max(dlzkadna), praca=sum(praca), output=sum(output))
stats_day <- all_statistics(groupped$praca, groupped$output)
stats_day
groupped <- ddply(all_data,~datum+fve,summarise, gho=sum(gho), oblacnost=sum(oblacnost),
teplota=sum(teplota), vietor=sum(vietor), vlhkost=sum(vlhkost),
dlzkadna=max(dlzkadna), praca=sum(praca), output=sum(output))
groupped
stats_day <- all_statistics(groupped$praca, groupped$output)
stats_day
source('~/GitHub/baka/R source/presentation_tests/paral_hod_all.R')
stopCluster(cl)
source('~/GitHub/baka/R source/presentation_tests/param1.R')
source('~/GitHub/baka/R source/presentation_tests/paral_hod_all.R')
stats
all_hours
prog.baseAll
actual
output
#pocet vsetkyc dni - pocitam percenta
prog.baseAll <- dbGetQuery(db.con, "select count(*) as ccc from (select distinct * from (select cas, fve from v_data) s1) s2")
prog.baseAll <- prog.baseAll$ccc
prog.opsAll <- length(tm.velkost) * length(f.ntree) * length(f.mtry) *
length(pod_gho) * length(pod_obl) * length(pod_tep) * length(pod_vie) *
length(pod_vlh) * length(pod_dlz) * length(pod_ele)
prog.baseAll <- prog.baseAll * prog.opsAll
i.pod_gho <- pod_gho
i.pod_obl <- pod_obl
i.pod_tep <- pod_tep
i.pod_vie <- pod_vie
i.pod_vlh <- pod_vlh
i.pod_dlz <- pod_dlz
i.pod_ele <- pod_ele
i.velkost <- tm.velkost
i.ntree <- f.ntree
i.mtry <- f.mtry
source('~/GitHub/baka/R source/presentation_tests/paral_hod_all.R')
stats
stats_day
db.drv <- dbDriver("PostgreSQL")
if (exists("db.con")) dbDisconnect(db.con)
db.con <- getConnection(db.drv)
all_data <-  dbGetQuery(db.con, "SELECT fve, datum, cas, gho, oblacnost,
teplota, vietor, vlhkost, dlzkadna, elev, praca
FROM v_data ORDER BY fve, cas")
all_data <- cbind(all_data, output)
to_see <- cbind(all_data, dif = abs(output - actual) * 100 / actual)
to_see <- arrange(to_see, to_see$dif)
groupped <- ddply(all_data,~datum+fve,summarise, gho=sum(gho), oblacnost=sum(oblacnost),
teplota=sum(teplota), vietor=sum(vietor), vlhkost=sum(vlhkost),
dlzkadna=max(dlzkadna), praca=sum(praca), output=sum(output))
stats_day <- all_statistics(groupped$praca, groupped$output)
stats_day
cc <- dbGetQuery(db.con, "select count(*) as cc from (select distinct * from (select cas, fve from v_data) s1) s2")$cc
cc
cc_all <- dbGetQuery(db.con, "select count(*) as cc from (select distinct * from (select cas, fve from v_data_all) s1) s2")$cc
cc_120 <- dbGetQuery(db.con, "select count(*) as cc from (select distinct * from (select cas, fve from v_data_120) s1) s2")$cc
perc_120 <- cc_120 * 100 / cc_all
perc_120
cc_120
cc_all
perc <- cc * 100 / cc_all
perc
source('~/.active-rstudio-document')
summ
sum_120
sum_all
source('~/.active-rstudio-document')
perc_summ
perc_sum_120
sum_all
source('~/.active-rstudio-document')
options(digits = 4)
source('~/.active-rstudio-document')
source('~/GitHub/baka/R source/presentation_tests/paral_hod_all.R')
stats
stats_day
source('~/GitHub/baka/R source/presentation_tests/paral_hod_all.R')
stats
stats_day
# db.drv <- dbDriver("PostgreSQL")
# if (exists("db.con")) dbDisconnect(db.con)
db.con <- getConnection(db.drv)
all_data <-  dbGetQuery(db.con, "SELECT fve, datum, cas, gho, oblacnost,
teplota, vietor, vlhkost, dlzkadna, elev, praca
FROM v_data_120 ORDER BY fve, cas")
all_data <- cbind(all_data, output)
to_see <- cbind(all_data, dif = abs(output - actual) * 100 / actual)
to_see <- arrange(to_see, to_see$dif)
groupped <- ddply(all_data,~datum+fve,summarise, gho=sum(gho), oblacnost=sum(oblacnost),
teplota=sum(teplota), vietor=sum(vietor), vlhkost=sum(vlhkost),
dlzkadna=max(dlzkadna), praca=sum(praca), output=sum(output))
stats_day <- all_statistics(groupped$praca, groupped$output)
# db.drv <- dbDriver("PostgreSQL")
# if (exists("db.con")) dbDisconnect(db.con)
db.con <- getConnection(db.drv)
all_data <-  dbGetQuery(db.con, "SELECT fve, datum, cas, gho, oblacnost,
teplota, vietor, vlhkost, dlzkadna, elev, praca
FROM v_data_120 ORDER BY fve, cas")
all_data <- cbind(all_data, output)
to_see <- cbind(all_data, dif = abs(output - actual) * 100 / actual)
to_see <- arrange(to_see, to_see$dif)
groupped <- ddply(all_data,~datum+fve,summarise, gho=sum(gho), oblacnost=sum(oblacnost),
teplota=sum(teplota), vietor=sum(vietor), vlhkost=sum(vlhkost),
dlzkadna=max(dlzkadna), praca=sum(praca), output=sum(output))
stats_day <- all_statistics(groupped$praca, groupped$output)
stats_day
source('~/GitHub/baka/R source/presentation_tests/paral_hod_all.R')
stats
stats_day
source('~/GitHub/baka/R source/presentation_tests/paral_hod_all.R')
source('~/GitHub/baka/R source/presentation_tests/paral_hod_all.R')
stats
stats_day
source('~/GitHub/baka/R source/presentation_tests/paral_hod_all.R')
stats
stats_day
source('~/GitHub/baka/R source/presentation_tests/param1.R')
stats
source('~/GitHub/baka/R source/presentation_tests/param1.R')
stats
source('~/GitHub/baka/R source/presentation_tests/param1.R')
stats
source('~/GitHub/baka/R source/presentation_tests/param1.R')
stats
source('~/GitHub/baka/R source/presentation_tests/param1.R')
stats
source('~/GitHub/baka/R source/presentation_tests/param1.R')
stats
source('~/GitHub/baka/R source/presentation_tests/paral_hod_all.R')
stats
source('~/GitHub/baka/R source/presentation_tests/paral_hod_all.R')
stats_day
source('~/GitHub/baka/R source/presentation_tests/paral_hod_all.R')
stats
stats_day
source('~/GitHub/baka/R source/presentation_tests/paral_hod_all.R')
stats
stats_day
source('~/GitHub/baka/R source/presentation_tests/paral_hod_all.R')
source('~/GitHub/baka/R source/presentation_tests/paral_hod_all.R')
source('~/GitHub/baka/R source/presentation_tests/paral_hod_megascript.R')
warnings()
if (write_results) {
for (name in names(stats_day)) {
if (is.infinite(stats_day[[name]]) | !is.numeric(stats_day[[name]]) | is.nan(stats_day[[name]])) stats_day[[name]] <- 999.999
}
insert <- sprintf("INSERT INTO t_experiment (cas_behu, metoda, param1, param2, param3, param4, param5,
N, MBE, RMBE, RMSE, RRMSE, MAE, RMAE, MPE, MAXAE, SD,
tm_velkost, tm_opis, tm_select, fve, den_hod,
pod_gho, pod_oblacnost, pod_teplota, pod_vietor, pod_vlhkost, pod_tlak, pod_dlzkadna, pod_azim, pod_elev,
in_gho, in_oblacnost, in_teplota, in_vietor, in_vlhkost, in_tlak, in_dlzkadna, in_azim, in_elev)
VALUES ('%s', '%s', '%s', '%s', '%s', '%s', '%s',
%d, %f, %f, %f, %f, %f, %f, %f, %f, %f,
%d, '%s', '%s', '%s', '%s',
%f, %f, %f, %f, %f, %f, %f, %f, %f,
%s, %s, %s, %s, %s, %s, %s, %s, %s);",
time.start, "random forest", "tm 30", "ntree 500", "mtry 2", "stats_den", "",
stats_day$N, stats_day$MBE, stats_day$RMBE, stats_day$RMSE, stats_day$RRMSE, stats_day$MAE, stats_day$RMAE, stats_day$MPE, stats_day$MAXAE, stats_day$SD,
30, "30 najpodob hodin", select, "vsetky", "hod",
i.pod_gho, i.pod_obl, i.pod_tep, i.pod_vie, i.pod_vlh, 0, i.pod_dlz, 0, i.pod_ele,
TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, TRUE, FALSE, FALSE)
db.result <- dbGetQuery(db.con, insert)
}
hourh
chosen_hours
hourh
chosen_hours[1:10,]
source('~/GitHub/baka/R source/presentation_tests/paral_hod_all.R')
stats_day
varImpPlot(forest)
forest <- randomForest(praca~gho+oblacnost+teplota+vietor+vlhkost+dlzkadna+elev,
data=train_set, ntree = i.ntree, mtry = i.mtry, importance=TRUE)
predic <-predict(forest, data.frame(gho = hourh[['gho']], oblacnost = hourh[['oblacnost']],
teplota = hourh[['teplota']], vietor = hourh[['vietor']],
vlhkost = hourh[['vlhkost']], dlzkadna = hourh[['dlzkadna']],
elev = hourh[['elev']]), type="response", norm.votes=TRUE)
source('~/GitHub/baka/R source/presentation_tests/paral_hod_all.R')
stats
stats_day
varImpPlot(forest)
i.fve
hourh
all_hours <- dbGetQuery(db.con, sprintf(select, i.fve))
ad_ncol <- ncol(all_hours)
maxims <- sapply(all_hours[,4:ad_ncol], max)
minims <- sapply(all_hours[,4:ad_ncol], min)
scale <- abs(maxims - minims)
all_hours <- data.matrix(all_hours)
chosen_hours <- all_hours
fve_actual <- chosen_hours[,'praca']
clusterExport(cl, list("chosen_hours", "all_hours", "scale",
"i.pod_gho", "i.pod_obl", "i.pod_tep", "i.pod_vie", "i.pod_dlz",
"i.pod_vlh", "i.pod_ele",
"i.ntree", "i.mtry", "i.velkost"))
fve_output <- parSapply(cl, 1:nrow(chosen_hours), function(y) {
hourh <- chosen_hours[y,]
potencial <- all_hours[all_hours[,'datum'] != hourh[['datum']],]
diff <- vector(mode = "numeric", length = nrow(potencial))
diff <- sapply(1:length(diff), function(x) {
ret <- abs(hourh[['gho']] - potencial[[x,'gho']]) * 100 / scale[['gho']] * i.pod_gho
ret <- ret + abs(hourh[['oblacnost']] - potencial[[x,'oblacnost']]) * 100 / scale[['oblacnost']] * i.pod_obl
ret <- ret + abs(hourh[['teplota']] - potencial[[x,'teplota']]) * 100 / scale[['teplota']] * i.pod_tep
ret <- ret + abs(hourh[['vietor']] - potencial[[x,'vietor']]) * 100 / scale[['vietor']] * i.pod_vie
ret <- ret + abs(hourh[['vlhkost']] - potencial[[x,'vlhkost']]) * 100 / scale[['vlhkost']] * i.pod_vlh
ret <- ret + abs(hourh[['dlzkadna']] - potencial[[x,'dlzkadna']]) * 100 / scale[['dlzkadna']] * i.pod_dlz
ret <- ret + abs(hourh[['elev']] - potencial[[x,'elev']]) * 100 / scale[['elev']] * i.pod_ele
return(ret)
})
train_set <- arrange(as.data.frame(potencial), diff)[1:i.velkost,]
forest <- randomForest(praca~gho+oblacnost+teplota+vietor+vlhkost+dlzkadna+elev,
data=train_set, ntree = i.ntree, mtry = i.mtry, importance=TRUE)
predic <-predict(forest, data.frame(gho = hourh[['gho']], oblacnost = hourh[['oblacnost']],
teplota = hourh[['teplota']], vietor = hourh[['vietor']],
vlhkost = hourh[['vlhkost']], dlzkadna = hourh[['dlzkadna']],
elev = hourh[['elev']]), type="response", norm.votes=TRUE)
#varImpPlot(forest)
return(predic)
})
cl <- makeCluster(4, type='SOCK')
clusterEvalQ(cl, format.time <- function(x) UseMethod("format.time"))
clusterEvalQ(cl, { library(plyr); library(randomForest) })
all_hours <- dbGetQuery(db.con, sprintf(select, i.fve))
ad_ncol <- ncol(all_hours)
maxims <- sapply(all_hours[,4:ad_ncol], max)
minims <- sapply(all_hours[,4:ad_ncol], min)
scale <- abs(maxims - minims)
all_hours <- data.matrix(all_hours)
chosen_hours <- all_hours
fve_actual <- chosen_hours[,'praca']
clusterExport(cl, list("chosen_hours", "all_hours", "scale",
"i.pod_gho", "i.pod_obl", "i.pod_tep", "i.pod_vie", "i.pod_dlz",
"i.pod_vlh", "i.pod_ele",
"i.ntree", "i.mtry", "i.velkost"))
fve_output <- parSapply(cl, 1:nrow(chosen_hours), function(y) {
hourh <- chosen_hours[y,]
potencial <- all_hours[all_hours[,'datum'] != hourh[['datum']],]
diff <- vector(mode = "numeric", length = nrow(potencial))
diff <- sapply(1:length(diff), function(x) {
ret <- abs(hourh[['gho']] - potencial[[x,'gho']]) * 100 / scale[['gho']] * i.pod_gho
ret <- ret + abs(hourh[['oblacnost']] - potencial[[x,'oblacnost']]) * 100 / scale[['oblacnost']] * i.pod_obl
ret <- ret + abs(hourh[['teplota']] - potencial[[x,'teplota']]) * 100 / scale[['teplota']] * i.pod_tep
ret <- ret + abs(hourh[['vietor']] - potencial[[x,'vietor']]) * 100 / scale[['vietor']] * i.pod_vie
ret <- ret + abs(hourh[['vlhkost']] - potencial[[x,'vlhkost']]) * 100 / scale[['vlhkost']] * i.pod_vlh
ret <- ret + abs(hourh[['dlzkadna']] - potencial[[x,'dlzkadna']]) * 100 / scale[['dlzkadna']] * i.pod_dlz
ret <- ret + abs(hourh[['elev']] - potencial[[x,'elev']]) * 100 / scale[['elev']] * i.pod_ele
return(ret)
})
train_set <- arrange(as.data.frame(potencial), diff)[1:i.velkost,]
forest <- randomForest(praca~gho+oblacnost+teplota+vietor+vlhkost+dlzkadna+elev,
data=train_set, ntree = i.ntree, mtry = i.mtry, importance=TRUE)
predic <-predict(forest, data.frame(gho = hourh[['gho']], oblacnost = hourh[['oblacnost']],
teplota = hourh[['teplota']], vietor = hourh[['vietor']],
vlhkost = hourh[['vlhkost']], dlzkadna = hourh[['dlzkadna']],
elev = hourh[['elev']]), type="response", norm.votes=TRUE)
#varImpPlot(forest)
return(predic)
})
all_hours <- dbGetQuery(db.con, sprintf(select, i.fve))
ad_ncol <- ncol(all_hours)
maxims <- sapply(all_hours[,4:ad_ncol], max)
minims <- sapply(all_hours[,4:ad_ncol], min)
scale <- abs(maxims - minims)
all_hours <- data.matrix(all_hours)
chosen_hours <- all_hours
fve_actual <- chosen_hours[,'praca']
clusterExport(cl, list("chosen_hours", "all_hours", "scale",
"i.pod_gho", "i.pod_obl", "i.pod_tep", "i.pod_vie", "i.pod_dlz",
"i.pod_vlh", "i.pod_ele",
"i.ntree", "i.mtry", "i.velkost"))
fve_output <- parSapply(cl, 1:nrow(chosen_hours), function(y) {
hourh <- chosen_hours[y,]
potencial <- all_hours[all_hours[,'datum'] != hourh[['datum']],]
diff <- vector(mode = "numeric", length = nrow(potencial))
diff <- sapply(1:length(diff), function(x) {
ret <- abs(hourh[['gho']] - potencial[[x,'gho']]) * 100 / scale[['gho']] * i.pod_gho
ret <- ret + abs(hourh[['oblacnost']] - potencial[[x,'oblacnost']]) * 100 / scale[['oblacnost']] * i.pod_obl
ret <- ret + abs(hourh[['teplota']] - potencial[[x,'teplota']]) * 100 / scale[['teplota']] * i.pod_tep
ret <- ret + abs(hourh[['vietor']] - potencial[[x,'vietor']]) * 100 / scale[['vietor']] * i.pod_vie
ret <- ret + abs(hourh[['vlhkost']] - potencial[[x,'vlhkost']]) * 100 / scale[['vlhkost']] * i.pod_vlh
ret <- ret + abs(hourh[['dlzkadna']] - potencial[[x,'dlzkadna']]) * 100 / scale[['dlzkadna']] * i.pod_dlz
ret <- ret + abs(hourh[['elev']] - potencial[[x,'elev']]) * 100 / scale[['elev']] * i.pod_ele
return(ret)
})
train_set <- arrange(as.data.frame(potencial), diff)[1:i.velkost,]
forest <- randomForest(praca~gho+oblacnost+teplota+vietor+vlhkost+dlzkadna+elev,
data=train_set, ntree = i.ntree, mtry = i.mtry, importance=TRUE)
predic <-predict(forest, data.frame(gho = hourh[['gho']], oblacnost = hourh[['oblacnost']],
teplota = hourh[['teplota']], vietor = hourh[['vietor']],
vlhkost = hourh[['vlhkost']], dlzkadna = hourh[['dlzkadna']],
elev = hourh[['elev']]), type="response", norm.votes=TRUE)
#varImpPlot(forest)
return(predic)
})
all_hours[,'datum']
hourh <- chosen_hours[y,]
hourh <- chosen_hours[1,]
potencial <- all_hours[all_hours[,'datum'] != hourh[['datum']],]
diff <- vector(mode = "numeric", length = nrow(potencial))
diff <- sapply(1:length(diff), function(x) {
ret <- abs(hourh[['gho']] - potencial[[x,'gho']]) * 100 / scale[['gho']] * i.pod_gho
ret <- ret + abs(hourh[['oblacnost']] - potencial[[x,'oblacnost']]) * 100 / scale[['oblacnost']] * i.pod_obl
ret <- ret + abs(hourh[['teplota']] - potencial[[x,'teplota']]) * 100 / scale[['teplota']] * i.pod_tep
ret <- ret + abs(hourh[['vietor']] - potencial[[x,'vietor']]) * 100 / scale[['vietor']] * i.pod_vie
ret <- ret + abs(hourh[['vlhkost']] - potencial[[x,'vlhkost']]) * 100 / scale[['vlhkost']] * i.pod_vlh
ret <- ret + abs(hourh[['dlzkadna']] - potencial[[x,'dlzkadna']]) * 100 / scale[['dlzkadna']] * i.pod_dlz
ret <- ret + abs(hourh[['elev']] - potencial[[x,'elev']]) * 100 / scale[['elev']] * i.pod_ele
return(ret)
})
scale
all_hours <- dbGetQuery(db.con, sprintf(select, i.fve))
ad_ncol <- ncol(all_hours)
maxims <- sapply(all_hours[,4:ad_ncol], max)
minims <- sapply(all_hours[,4:ad_ncol], min)
scale <- abs(maxims - minims)
all_hours <- data.matrix(all_hours)
all_hours
ad_ncol
maxims
all_hours[,4:ad_ncol]
sapply(all_hours[,4:ad_ncol], max)
all_hours[,4:ad_ncol]
all_hours[1:10,4:ad_ncol]
sapply(all_hours[1:10,4:ad_ncol], max)
apply(all_hours[,4:ad_ncol], 2, max)
ad_ncol <- ncol(all_hours)
maxims <- apply(all_hours[,4:ad_ncol], 2, max)
minims <- apply(all_hours[,4:ad_ncol], 2, min)
scale <- abs(maxims - minims)
all_hours <- data.matrix(all_hours)
scale
chosen_hours <- all_hours
fve_actual <- chosen_hours[,'praca']
clusterExport(cl, list("chosen_hours", "all_hours", "scale",
"i.pod_gho", "i.pod_obl", "i.pod_tep", "i.pod_vie", "i.pod_dlz",
"i.pod_vlh", "i.pod_ele",
"i.ntree", "i.mtry", "i.velkost"))
fve_output <- parSapply(cl, 1:nrow(chosen_hours), function(y) {
hourh <- chosen_hours[1,]
potencial <- all_hours[all_hours[,'datum'] != hourh[['datum']],]
diff <- vector(mode = "numeric", length = nrow(potencial))
diff <- sapply(1:length(diff), function(x) {
ret <- abs(hourh[['gho']] - potencial[[x,'gho']]) * 100 / scale[['gho']] * i.pod_gho
ret <- ret + abs(hourh[['oblacnost']] - potencial[[x,'oblacnost']]) * 100 / scale[['oblacnost']] * i.pod_obl
ret <- ret + abs(hourh[['teplota']] - potencial[[x,'teplota']]) * 100 / scale[['teplota']] * i.pod_tep
ret <- ret + abs(hourh[['vietor']] - potencial[[x,'vietor']]) * 100 / scale[['vietor']] * i.pod_vie
ret <- ret + abs(hourh[['vlhkost']] - potencial[[x,'vlhkost']]) * 100 / scale[['vlhkost']] * i.pod_vlh
ret <- ret + abs(hourh[['dlzkadna']] - potencial[[x,'dlzkadna']]) * 100 / scale[['dlzkadna']] * i.pod_dlz
ret <- ret + abs(hourh[['elev']] - potencial[[x,'elev']]) * 100 / scale[['elev']] * i.pod_ele
return(ret)
})
train_set <- arrange(as.data.frame(potencial), diff)[1:i.velkost,]
forest <- randomForest(praca~gho+oblacnost+teplota+vietor+vlhkost+dlzkadna+elev,
data=train_set, ntree = i.ntree, mtry = i.mtry, importance=TRUE)
predic <-predict(forest, data.frame(gho = hourh[['gho']], oblacnost = hourh[['oblacnost']],
teplota = hourh[['teplota']], vietor = hourh[['vietor']],
vlhkost = hourh[['vlhkost']], dlzkadna = hourh[['dlzkadna']],
elev = hourh[['elev']]), type="response", norm.votes=TRUE)
#varImpPlot(forest)
return(predic)
})
chosen_hours <- all_hours
fve_actual <- chosen_hours[,'praca']
clusterExport(cl, list("chosen_hours", "all_hours", "scale",
"i.pod_gho", "i.pod_obl", "i.pod_tep", "i.pod_vie", "i.pod_dlz",
"i.pod_vlh", "i.pod_ele",
"i.ntree", "i.mtry", "i.velkost"))
source('~/GitHub/baka/R source/presentation_tests/paral_hod_all.R')
varImpPlot(forest)
stats
stats_day
all_hours <- dbGetQuery(db.con, sprintf(select, i.fve))
ad_ncol <- ncol(all_hours)
maxims <- apply(all_hours[,4:ad_ncol], 2, max)
minims <- apply(all_hours[,4:ad_ncol], 2, min)
scale <- abs(maxims - minims)
all_hours <- data.matrix(all_hours)
chosen_hours <- all_hours
fve_actual <- chosen_hours[,'praca']
clusterExport(cl, list("chosen_hours", "all_hours", "scale",
"i.pod_gho", "i.pod_obl", "i.pod_tep", "i.pod_vie", "i.pod_dlz",
"i.pod_vlh", "i.pod_ele",
"i.ntree", "i.mtry", "i.velkost"))
cl <- makeCluster(4, type='SOCK')
clusterEvalQ(cl, format.time <- function(x) UseMethod("format.time"))
clusterEvalQ(cl, { library(plyr); library(randomForest) })
clusterExport(cl, list("chosen_hours", "all_hours", "scale",
"i.pod_gho", "i.pod_obl", "i.pod_tep", "i.pod_vie", "i.pod_dlz",
"i.pod_vlh", "i.pod_ele",
"i.ntree", "i.mtry", "i.velkost"))
fve_output <- parSapply(cl, 1:nrow(chosen_hours), function(y) {
hourh <- chosen_hours[y,]
potencial <- all_hours[all_hours[,'datum'] != hourh[['datum']],]
diff <- vector(mode = "numeric", length = nrow(potencial))
diff <- sapply(1:length(diff), function(x) {
ret <- abs(hourh[['gho']] - potencial[[x,'gho']]) * 100 / scale[['gho']] * i.pod_gho
ret <- ret + abs(hourh[['oblacnost']] - potencial[[x,'oblacnost']]) * 100 / scale[['oblacnost']] * i.pod_obl
ret <- ret + abs(hourh[['teplota']] - potencial[[x,'teplota']]) * 100 / scale[['teplota']] * i.pod_tep
ret <- ret + abs(hourh[['vietor']] - potencial[[x,'vietor']]) * 100 / scale[['vietor']] * i.pod_vie
ret <- ret + abs(hourh[['vlhkost']] - potencial[[x,'vlhkost']]) * 100 / scale[['vlhkost']] * i.pod_vlh
ret <- ret + abs(hourh[['dlzkadna']] - potencial[[x,'dlzkadna']]) * 100 / scale[['dlzkadna']] * i.pod_dlz
ret <- ret + abs(hourh[['elev']] - potencial[[x,'elev']]) * 100 / scale[['elev']] * i.pod_ele
return(ret)
})
train_set <- arrange(as.data.frame(potencial), diff)[1:i.velkost,]
forest <- randomForest(praca~gho+oblacnost+teplota+vietor+vlhkost+dlzkadna+elev,
data=train_set, ntree = i.ntree, mtry = i.mtry, importance=TRUE)
predic <-predict(forest, data.frame(gho = hourh[['gho']], oblacnost = hourh[['oblacnost']],
teplota = hourh[['teplota']], vietor = hourh[['vietor']],
vlhkost = hourh[['vlhkost']], dlzkadna = hourh[['dlzkadna']],
elev = hourh[['elev']]), type="response", norm.votes=TRUE)
#varImpPlot(forest)
return(predic)
})
forest
stopCluster(cl)
source('~/GitHub/baka/R source/presentation_tests/paral_hod_all.R')
stats
stats_day
forest
ad_ncol <- ncol(all_hours)
maxims <- apply(all_hours[,4:ad_ncol], 2, max)
minims <- apply(all_hours[,4:ad_ncol], 2, min)
scale <- abs(maxims - minims)
all_hours <- data.matrix(all_hours)
chosen_hours <- all_hours
fve_actual <- chosen_hours[,'praca']
hourh <- chosen_hours[1,]
potencial <- all_hours[all_hours[,'datum'] != hourh[['datum']],]
diff <- vector(mode = "numeric", length = nrow(potencial))
diff <- sapply(1:length(diff), function(x) {
ret <- abs(hourh[['gho']] - potencial[[x,'gho']]) * 100 / scale[['gho']] * i.pod_gho
ret <- ret + abs(hourh[['oblacnost']] - potencial[[x,'oblacnost']]) * 100 / scale[['oblacnost']] * i.pod_obl
ret <- ret + abs(hourh[['teplota']] - potencial[[x,'teplota']]) * 100 / scale[['teplota']] * i.pod_tep
ret <- ret + abs(hourh[['vietor']] - potencial[[x,'vietor']]) * 100 / scale[['vietor']] * i.pod_vie
ret <- ret + abs(hourh[['vlhkost']] - potencial[[x,'vlhkost']]) * 100 / scale[['vlhkost']] * i.pod_vlh
ret <- ret + abs(hourh[['dlzkadna']] - potencial[[x,'dlzkadna']]) * 100 / scale[['dlzkadna']] * i.pod_dlz
ret <- ret + abs(hourh[['elev']] - potencial[[x,'elev']]) * 100 / scale[['elev']] * i.pod_ele
return(ret)
})
train_set <- arrange(as.data.frame(potencial), diff)[1:i.velkost,]
forest <- randomForest(praca~gho+oblacnost+teplota+vietor+vlhkost+dlzkadna+elev,
data=train_set, ntree = i.ntree, mtry = i.mtry, importance=TRUE)
predic <-predict(forest, data.frame(gho = hourh[['gho']], oblacnost = hourh[['oblacnost']],
teplota = hourh[['teplota']], vietor = hourh[['vietor']],
vlhkost = hourh[['vlhkost']], dlzkadna = hourh[['dlzkadna']],
elev = hourh[['elev']]), type="response", norm.votes=TRUE)
forest
varImpPlot(forest)
source('~/GitHub/baka/R source/presentation_tests/paral_hod_megascript.R')
source('~/GitHub/baka/R source/presentation_tests/paral_hod_megascript.R')
source('~/GitHub/baka/R source/presentation_tests/paral_hod_megascript.R')
source('~/GitHub/baka/R source/presentation_tests/paral_hod_megascript.R')
source('~/GitHub/baka/R source/presentation_tests/paral_hod_megascript.R')
source('~/GitHub/baka/R source/presentation_tests/paral_hod_megascript.R')
